import streamlit as st
import google.generativeai as genai

# --- CONFIGURACI√ìN VISUAL ---
st.set_page_config(page_title="Mi Super IA", page_icon="üß†", layout="centered")

# T√≠tulo principal
st.title("üß† Super Asistente IA")
st.caption("Pregunta lo que quieras. Yo analizo el tema y me vuelvo experto.")

# --- BARRA LATERAL (Para tu llave) ---
with st.sidebar:
    st.header("Configuraci√≥n")
    api_key = st.text_input("Pega tu API Key aqu√≠:", type="password")
    st.info("Esta IA detecta autom√°ticamente si hablas de medicina, c√≥digo o historia y se adapta.")

# --- CEREBRO DE LA IA ---
if api_key:
    genai.configure(api_key=api_key)
    
    # AQU√ç EST√Å TU INSTRUCCI√ìN MAESTRA "CAMALE√ìN"
    instrucciones = """
    Eres una Inteligencia Artificial Avanzada y Autom√°tica.
    1. TU MISI√ìN: Analizar la pregunta del usuario e identificar el tema (Medicina, Programaci√≥n, Historia, Fitness, etc.).
    2. ADAPTACI√ìN: Transf√≥rmate en el mayor experto mundial de ese tema.
    3. RESPUESTA: No des res√∫menes simples. Investiga a fondo, da detalles t√©cnicos, dosis (si es medicina), sintaxis (si es c√≥digo) o fechas exactas.
    4. ESTILO: Responde en espa√±ol, usa formato Markdown (negritas, listas) para que se vea profesional.
    """
    
    # Usamos el modelo r√°pido que ya sabemos que tienes
    model = genai.GenerativeModel('gemini-2.0-flash', system_instruction=instrucciones)

    # Historial de chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Mostrar mensajes viejos
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Cuadro de entrada
    if prompt := st.chat_input("Escribe aqu√≠ (Ej: ¬øQu√© es el paracetamol?)..."):
        # Guardar lo que escribiste
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generar respuesta
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            try:
                # Enviamos el historial para que tenga memoria
                chat = model.start_chat(history=[
                    {"role": m["role"], "parts": [m["content"]]} 
                    for m in st.session_state.messages[:-1]
                ])
                
                # Efecto de escritura
                full_response = ""
                response = chat.send_message(prompt, stream=True)
                
                for chunk in response:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
                message_placeholder.markdown(full_response)
                
                # Guardar respuesta de IA
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                st.error(f"Error: {e}")

else:
    st.warning("üëà Por favor, pon tu API Key en la izquierda para iniciar.")